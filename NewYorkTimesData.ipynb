{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **New York Times Data Collection**"
      ],
      "metadata": {
        "id": "YJR0I4Fw8meH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing New York Times News Category Dataset and Sentiment Analysis"
      ],
      "metadata": {
        "id": "RGBx-Ega1Xzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textblob"
      ],
      "metadata": {
        "id": "EQqXvthSv-LX",
        "outputId": "1ccfb224-ae0a-4bd2-f054-f936b8711166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "EILaJ0YJxGkG",
        "outputId": "b7ff3143-e69c-4c8b-defb-84075d072ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "apikey = os.getenv('NYTIMES_APIKEY', 'SqzyHe7mmHI7o9uARoryVwi8wCVHdKzJ')\n",
        "\n",
        "start_date = datetime.strptime('2022-09-13', \"%Y-%m-%d\")\n",
        "end_date = datetime.strptime('2023-03-13', \"%Y-%m-%d\")\n",
        "\n",
        "ny_data = {}\n",
        "all_articles = []\n",
        "\n",
        "# Iterate through months in the date range\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    year = current_date.year\n",
        "    month = current_date.month\n",
        "\n",
        "    query_url = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={apikey}\"\n",
        "\n",
        "    r = requests.get(query_url)\n",
        "    ny_data.update(r.json())\n",
        "    all_articles.extend(ny_data['response']['docs'])\n",
        "\n",
        "    # Move to the next month\n",
        "    if current_date.month == 12:\n",
        "        current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
        "    else:\n",
        "        current_date = current_date.replace(month=current_date.month + 1)\n",
        "\n",
        "# Filter articles and calculate sentiment\n",
        "filtered_articles = []\n",
        "for doc in all_articles:\n",
        "    sec_name = doc['section_name']\n",
        "    if sec_name not in ['Business Day', 'Technology', 'Real Estate']:\n",
        "        continue\n",
        "\n",
        "    pub_date = doc['pub_date']\n",
        "    date = datetime.strptime(pub_date.split('T')[0], \"%Y-%m-%d\").date()\n",
        "    if date < start_date.date() or date > end_date.date():\n",
        "        continue\n",
        "\n",
        "    headline = doc['headline']['main']\n",
        "    abstract = doc['abstract']\n",
        "\n",
        "    headline_sentiment = sia.polarity_scores(headline)['compound']\n",
        "    abstract_sentiment = sia.polarity_scores(abstract)['compound']\n",
        "\n",
        "    filtered_articles.append({\n",
        "        'pub_date': str(date),\n",
        "        'headline': headline,\n",
        "        'abstract': abstract,\n",
        "        'section': sec_name,\n",
        "        'headline_sentiment': headline_sentiment,\n",
        "        'abstract_sentiment': abstract_sentiment\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "cleaned_ny_data_df = pd.DataFrame(filtered_articles)\n",
        "\n",
        "# Group by date and calculate mean and median sentiment scores\n",
        "grouped_data = cleaned_ny_data_df.groupby('pub_date').agg({\n",
        "    'headline_sentiment': ['mean', 'median'],\n",
        "    'abstract_sentiment': ['mean', 'median']\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten the multi-level column names\n",
        "grouped_data.columns = ['_'.join(col).strip() for col in grouped_data.columns.values]\n",
        "\n",
        "# Rename columns\n",
        "grouped_data.columns = ['Date', 'Headline Mean', 'Headline Median', 'Body Mean', 'Body Median']\n",
        "\n",
        "# Set the 'Date' column as the index of the grouped_data DataFrame\n",
        "grouped_data.set_index('Date', inplace=True)\n",
        "\n",
        "# Round the sentiment scores to two decimal places\n",
        "grouped_data_rounded = grouped_data.round(2)\n",
        "\n",
        "# Save the entire rounded grouped_data DataFrame to a CSV file\n",
        "grouped_data_rounded.to_csv(\"ny_times_grouped_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFz68TRAtsCA",
        "outputId": "98421856-4af0-43c5-baaf-33cddeef6c03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}